{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fd1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "import torchvision.models as torch_models\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487d229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "dataset_path = '/home/wyundi/Server/Courses/CS546/project/data/cat/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace8aaf",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6e20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cat_df.iloc[0].at['image_base64_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72d1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(cat_df.shape[0]):\n",
    "#     img = base64.b64decode(cat_df.iloc[i].at['image_base64_string'])\n",
    "#     img = Image.open(io.BytesIO(img))\n",
    "#     img_np = np.array(img)\n",
    "#     print(img_np.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42843e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = base64.b64decode(cat_df.iloc[3].at['image_base64_string'])\n",
    "# img = Image.open(io.BytesIO(img))\n",
    "# plt.imshow(img)\n",
    "\n",
    "# label = cat_df.iloc[3].at['label']\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688fa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = img.resize((224, 224))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a10103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = cat_df.iloc[0].at['label']\n",
    "# print(label)\n",
    "# print(type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3963e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_np = np.array(img)\n",
    "# print(img_np.shape)\n",
    "\n",
    "# img_tensor = torch.tensor(img_np.transpose(2, 0, 1), dtype=torch.float32)\n",
    "# print(img_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629b371",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ddd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "\n",
    "def set_device(net, device='GPU'):\n",
    "    if device == 'GPU':\n",
    "        torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataRarallel(model)\n",
    "\n",
    "    net = net.to(torch_device)\n",
    "    return net, torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a4b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.__dataset_path = path\n",
    "        \n",
    "        self.__transforms = torch.nn.Sequential(\n",
    "            T.Resize((224, 224)),\n",
    "            T.RandomResizedCrop(224),\n",
    "            T.RandomHorizontalFlip(),\n",
    "        )\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            self.__img_path = path + '/' + filename\n",
    "            \n",
    "            self.data_list.append(self.__img_path)\n",
    "            self.label_list.append(0 if filename.split('.')[0] == 'cat' else 1)\n",
    "            \n",
    "        self.data = list(zip(self.data_list, self.label_list))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        self.__img_path, self.__img_label = self.data[index]\n",
    "        \n",
    "        self.__img = Image.open(self.__img_path)\n",
    "        self.__img = self.__transforms(self.__img)\n",
    "        self.__img_np = np.array(self.__img)\n",
    "        \n",
    "        self.__img_label = torch.tensor(self.__img_label, dtype=torch.long)\n",
    "        self.__img_tensor = torch.tensor(self.__img_np.transpose(2, 0, 1), dtype=torch.float32)\n",
    "        \n",
    "        self.__mean, self.__std = self.__img_tensor.mean(), self.__img_tensor.std()\n",
    "        self.__std = 1e-03 if self.__std == 0 else self.__std\n",
    "    \n",
    "        self.__transforms_norm = torch.nn.Sequential(\n",
    "            T.Normalize(self.__mean, self.__std)\n",
    "        )\n",
    "\n",
    "        self.__img_tensor = self.__transforms_norm(self.__img_tensor)\n",
    "        \n",
    "        return (self.__img_tensor, self.__img_label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name_list\n",
    "        \n",
    "cat_dataset = dataset(dataset_path)\n",
    "dl = DataLoader(cat_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# for step, (inputs, labels) in enumerate(dl):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20fad20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convnet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Flatten(start_dim=1, end_dim=3)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Convnet                                  --                        --\n",
      "├─Sequential: 1-1                        [16, 9216]                --\n",
      "│    └─Conv2d: 2-1                       [16, 64, 224, 224]        1,792\n",
      "│    └─ReLU: 2-2                         [16, 64, 224, 224]        --\n",
      "│    └─MaxPool2d: 2-3                    [16, 64, 112, 112]        --\n",
      "│    └─Conv2d: 2-4                       [16, 192, 112, 112]       110,784\n",
      "│    └─ReLU: 2-5                         [16, 192, 112, 112]       --\n",
      "│    └─MaxPool2d: 2-6                    [16, 192, 55, 55]         --\n",
      "│    └─Conv2d: 2-7                       [16, 384, 55, 55]         663,936\n",
      "│    └─ReLU: 2-8                         [16, 384, 55, 55]         --\n",
      "│    └─MaxPool2d: 2-9                    [16, 384, 27, 27]         --\n",
      "│    └─Conv2d: 2-10                      [16, 256, 27, 27]         884,992\n",
      "│    └─ReLU: 2-11                        [16, 256, 27, 27]         --\n",
      "│    └─MaxPool2d: 2-12                   [16, 256, 13, 13]         --\n",
      "│    └─Conv2d: 2-13                      [16, 256, 13, 13]         590,080\n",
      "│    └─ReLU: 2-14                        [16, 256, 13, 13]         --\n",
      "│    └─MaxPool2d: 2-15                   [16, 256, 6, 6]           --\n",
      "│    └─Flatten: 2-16                     [16, 9216]                --\n",
      "├─Sequential: 1-2                        [16, 2]                   --\n",
      "│    └─Linear: 2-17                      [16, 4096]                37,752,832\n",
      "│    └─ReLU: 2-18                        [16, 4096]                --\n",
      "│    └─BatchNorm1d: 2-19                 [16, 4096]                8,192\n",
      "│    └─Linear: 2-20                      [16, 2048]                8,390,656\n",
      "│    └─ReLU: 2-21                        [16, 2048]                --\n",
      "│    └─BatchNorm1d: 2-22                 [16, 2048]                4,096\n",
      "│    └─Linear: 2-23                      [16, 2]                   4,098\n",
      "==========================================================================================\n",
      "Total params: 48,411,458\n",
      "Trainable params: 48,411,458\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 68.46\n",
      "==========================================================================================\n",
      "Input size (MB): 9.63\n",
      "Forward/backward pass size (MB): 899.01\n",
      "Params size (MB): 193.65\n",
      "Estimated Total Size (MB): 1102.29\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class Convnet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(Convnet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten(start_dim=1, end_dim=3)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Net = Convnet(2)\n",
    "input_shape = (16, 3, 224, 224)\n",
    "\n",
    "print(Net)\n",
    "\n",
    "print(summary(Net, input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704b7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(3*3*64,10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b13cf3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for classification\n",
    "\n",
    "def calc_acc(out, labels):\n",
    "    num = out.size(0)\n",
    "    prediction = out.argmax(dim=1)\n",
    "    return (prediction == labels).sum().item()/num\n",
    "\n",
    "def evaluate(model, torch_device, loss_func, dataloader, method='classification'):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (inputs, labels) in enumerate(dataloader):\n",
    "            \n",
    "            inputs = inputs.to(torch_device)\n",
    "            labels = labels.to(torch_device)\n",
    "\n",
    "            out = model(inputs)\n",
    "            loss_list.append(loss_func(out, labels))\n",
    "\n",
    "            if method == 'classification':\n",
    "                acc_list.append(calc_acc(out, labels))\n",
    "\n",
    "        loss = torch.mean(torch.tensor(loss_list))\n",
    "\n",
    "    if method == 'classification':\n",
    "        acc = torch.mean(torch.tensor(acc_list, dtype=torch.float32))\n",
    "        return loss, acc\n",
    "    elif method == 'regression':\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a48164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train function\n",
    "\n",
    "def train_model(model, train_dataset, test_dataset, batch = 256, epochs=50,\n",
    "                lr=0.005, class_weights = None, weight_decay = 0):\n",
    "\n",
    "    # train_history\n",
    "    train_history = {}\n",
    "    train_history['train_loss'] = []\n",
    "    train_history['train_acc'] = []\n",
    "\n",
    "    train_history['test_loss'] = []\n",
    "    train_history['test_acc'] = []\n",
    "\n",
    "    # set device\n",
    "    model, torch_device = set_device(model)\n",
    "    \n",
    "    if class_weights != None:\n",
    "        class_weights = class_weights.to(torch_device)\n",
    "\n",
    "    # Dataloader\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch, shuffle=True, drop_last=True)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=batch, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # optimzer and loss_func\n",
    "    optimzer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False)\n",
    "    loss_func = nn.CrossEntropyLoss(weight = class_weights)\n",
    "\n",
    "    # train_process\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for step, (inputs, labels) in enumerate(train_dl):\n",
    "            \n",
    "            inputs = inputs.to(torch_device)\n",
    "            labels = labels.to(torch_device)\n",
    "\n",
    "            out = model(inputs)\n",
    "            loss = loss_func(out, labels)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            \n",
    "            # output\n",
    "            train_loss, train_acc = evaluate(model, torch_device, loss_func, train_dl)\n",
    "            test_loss, test_acc = evaluate(model, torch_device, loss_func, test_dl)\n",
    "\n",
    "            print(  'Epoch:', epoch+1, '/', epochs, ', '\\\n",
    "                    'train_loss: {loss:.5f}, '.format(loss = train_loss), \\\n",
    "                    'train_acc: {acc:.5f}, '.format(acc = train_acc), \\\n",
    "                    'test_loss: {loss:.5f}, '.format(loss = test_loss), \\\n",
    "                    'test_acc: {acc:.5f}'.format(acc = test_acc))\n",
    "\n",
    "            train_history['train_loss'].append(train_loss)\n",
    "            train_history['train_acc'].append(train_acc)\n",
    "\n",
    "            train_history['test_loss'].append(test_loss)\n",
    "            train_history['test_acc'].append(test_acc)\n",
    "  \n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df68d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "cat_dataset = dataset(dataset_path)\n",
    "\n",
    "split_rate = 0.9\n",
    "train_size = int(split_rate * len(cat_dataset))\n",
    "test_size = len(cat_dataset) - train_size\n",
    "\n",
    "print(test_size)\n",
    "\n",
    "train_dataset, test_dataset = random_split(cat_dataset, [train_size, test_size])\n",
    "\n",
    "batch = 512\n",
    "epochs = 10\n",
    "lr = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f6c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN                                      --                        --\n",
      "├─Sequential: 1-1                        [512, 16, 55, 55]         --\n",
      "│    └─Conv2d: 2-1                       [512, 16, 111, 111]       448\n",
      "│    └─BatchNorm2d: 2-2                  [512, 16, 111, 111]       32\n",
      "│    └─ReLU: 2-3                         [512, 16, 111, 111]       --\n",
      "│    └─MaxPool2d: 2-4                    [512, 16, 55, 55]         --\n",
      "├─Sequential: 1-2                        [512, 32, 13, 13]         --\n",
      "│    └─Conv2d: 2-5                       [512, 32, 27, 27]         4,640\n",
      "│    └─BatchNorm2d: 2-6                  [512, 32, 27, 27]         64\n",
      "│    └─ReLU: 2-7                         [512, 32, 27, 27]         --\n",
      "│    └─MaxPool2d: 2-8                    [512, 32, 13, 13]         --\n",
      "├─Sequential: 1-3                        [512, 64, 3, 3]           --\n",
      "│    └─Conv2d: 2-9                       [512, 64, 6, 6]           18,496\n",
      "│    └─BatchNorm2d: 2-10                 [512, 64, 6, 6]           128\n",
      "│    └─ReLU: 2-11                        [512, 64, 6, 6]           --\n",
      "│    └─MaxPool2d: 2-12                   [512, 64, 3, 3]           --\n",
      "├─Linear: 1-4                            [512, 10]                 5,770\n",
      "├─Dropout: 1-5                           --                        --\n",
      "├─Linear: 1-6                            --                        (recursive)\n",
      "├─ReLU: 1-7                              [512, 10]                 --\n",
      "├─Linear: 1-8                            [512, 2]                  22\n",
      "==========================================================================================\n",
      "Total params: 29,600\n",
      "Trainable params: 29,600\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.90\n",
      "==========================================================================================\n",
      "Input size (MB): 308.28\n",
      "Forward/backward pass size (MB): 1824.96\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 2133.36\n",
      "==========================================================================================\n",
      "Epoch: 1 / 10 , train_loss: 0.68442,  train_acc: 0.56018,  test_loss: 0.67455,  test_acc: 0.57324\n",
      "Epoch: 1 / 10 , train_loss: 0.69820,  train_acc: 0.54015,  test_loss: 0.69796,  test_acc: 0.53809\n",
      "Epoch: 1 / 10 , train_loss: 0.66375,  train_acc: 0.59648,  test_loss: 0.66390,  test_acc: 0.59082\n",
      "Epoch: 1 / 10 , train_loss: 0.67337,  train_acc: 0.58544,  test_loss: 0.66181,  test_acc: 0.60596\n",
      "Epoch: 1 / 10 , train_loss: 0.67531,  train_acc: 0.58330,  test_loss: 0.66659,  test_acc: 0.59863\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train Model\n",
    "\"\"\"\n",
    "\n",
    "# load model\n",
    "# model = Convnet(2)\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('/home/wyundi/Server/Courses/CS546/project/repo/M_Hub/src/ipynb/cat.pth'))\n",
    "print(summary(model, (batch, 3, 224, 224)))\n",
    "\n",
    "# train\n",
    "hist = train_model(model, train_dataset, test_dataset, batch, epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52b44ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/wyundi/Server/Courses/CS546/project/repo/M_Hub/src/ipynb/cat.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f19fa2",
   "metadata": {},
   "source": [
    "## Export model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50df783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
