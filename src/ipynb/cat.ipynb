{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666ea814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "import torchvision.models as torch_models\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10c5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "dataset_path = '/home/wyundi/Server/Courses/CS546/project/data/cat/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c17f7b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0078a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "\n",
    "def set_device(net, device='GPU'):\n",
    "    if device == 'GPU':\n",
    "        torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataRarallel(model)\n",
    "\n",
    "    net = net.to(torch_device)\n",
    "    return net, torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9c1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.__dataset_path = path\n",
    "        \n",
    "        self.__transforms = torch.nn.Sequential(\n",
    "            T.Resize((224, 224)),\n",
    "            T.RandomResizedCrop(224),\n",
    "            T.RandomHorizontalFlip(),\n",
    "        )\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            self.__img_path = path + '/' + filename\n",
    "            \n",
    "            self.data_list.append(self.__img_path)\n",
    "            self.label_list.append(0 if filename.split('.')[0] == 'cat' else 1)\n",
    "            \n",
    "        self.data = list(zip(self.data_list, self.label_list))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        self.__img_path, self.__img_label = self.data[index]\n",
    "        \n",
    "        self.__img = Image.open(self.__img_path)\n",
    "        self.__img = self.__transforms(self.__img)\n",
    "        self.__img_np = np.array(self.__img)\n",
    "        \n",
    "        self.__img_label = torch.tensor(self.__img_label, dtype=torch.long)\n",
    "        self.__img_tensor = torch.tensor(self.__img_np.transpose(2, 0, 1), dtype=torch.float32)\n",
    "        \n",
    "        self.__mean, self.__std = self.__img_tensor.mean(), self.__img_tensor.std()\n",
    "        self.__std = 1e-03 if self.__std == 0 else self.__std\n",
    "    \n",
    "        self.__transforms_norm = torch.nn.Sequential(\n",
    "            T.Normalize(self.__mean, self.__std)\n",
    "        )\n",
    "\n",
    "        self.__img_tensor = self.__transforms_norm(self.__img_tensor)\n",
    "        \n",
    "        return (self.__img_tensor, self.__img_label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name_list\n",
    "        \n",
    "cat_dataset = dataset(dataset_path)\n",
    "dl = DataLoader(cat_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# for step, (inputs, labels) in enumerate(dl):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca891fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convnet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Flatten(start_dim=1, end_dim=3)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Convnet                                  --                        --\n",
      "├─Sequential: 1-1                        [16, 9216]                --\n",
      "│    └─Conv2d: 2-1                       [16, 64, 224, 224]        1,792\n",
      "│    └─ReLU: 2-2                         [16, 64, 224, 224]        --\n",
      "│    └─MaxPool2d: 2-3                    [16, 64, 112, 112]        --\n",
      "│    └─Conv2d: 2-4                       [16, 192, 112, 112]       110,784\n",
      "│    └─ReLU: 2-5                         [16, 192, 112, 112]       --\n",
      "│    └─MaxPool2d: 2-6                    [16, 192, 55, 55]         --\n",
      "│    └─Conv2d: 2-7                       [16, 384, 55, 55]         663,936\n",
      "│    └─ReLU: 2-8                         [16, 384, 55, 55]         --\n",
      "│    └─MaxPool2d: 2-9                    [16, 384, 27, 27]         --\n",
      "│    └─Conv2d: 2-10                      [16, 256, 27, 27]         884,992\n",
      "│    └─ReLU: 2-11                        [16, 256, 27, 27]         --\n",
      "│    └─MaxPool2d: 2-12                   [16, 256, 13, 13]         --\n",
      "│    └─Conv2d: 2-13                      [16, 256, 13, 13]         590,080\n",
      "│    └─ReLU: 2-14                        [16, 256, 13, 13]         --\n",
      "│    └─MaxPool2d: 2-15                   [16, 256, 6, 6]           --\n",
      "│    └─Flatten: 2-16                     [16, 9216]                --\n",
      "├─Sequential: 1-2                        [16, 2]                   --\n",
      "│    └─Linear: 2-17                      [16, 4096]                37,752,832\n",
      "│    └─ReLU: 2-18                        [16, 4096]                --\n",
      "│    └─BatchNorm1d: 2-19                 [16, 4096]                8,192\n",
      "│    └─Linear: 2-20                      [16, 2048]                8,390,656\n",
      "│    └─ReLU: 2-21                        [16, 2048]                --\n",
      "│    └─BatchNorm1d: 2-22                 [16, 2048]                4,096\n",
      "│    └─Linear: 2-23                      [16, 2]                   4,098\n",
      "==========================================================================================\n",
      "Total params: 48,411,458\n",
      "Trainable params: 48,411,458\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 68.46\n",
      "==========================================================================================\n",
      "Input size (MB): 9.63\n",
      "Forward/backward pass size (MB): 899.01\n",
      "Params size (MB): 193.65\n",
      "Estimated Total Size (MB): 1102.29\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class Convnet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(Convnet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten(start_dim=1, end_dim=3)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Net = Convnet(2)\n",
    "input_shape = (16, 3, 224, 224)\n",
    "\n",
    "print(Net)\n",
    "\n",
    "print(summary(Net, input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c5ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(3*3*64,10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99d810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for classification\n",
    "\n",
    "def calc_acc(out, labels):\n",
    "    num = out.size(0)\n",
    "    prediction = out.argmax(dim=1)\n",
    "    return (prediction == labels).sum().item()/num\n",
    "\n",
    "def evaluate(model, torch_device, loss_func, dataloader, method='classification'):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (inputs, labels) in enumerate(dataloader):\n",
    "            \n",
    "            inputs = inputs.to(torch_device)\n",
    "            labels = labels.to(torch_device)\n",
    "\n",
    "            out = model(inputs)\n",
    "            loss_list.append(loss_func(out, labels))\n",
    "\n",
    "            if method == 'classification':\n",
    "                acc_list.append(calc_acc(out, labels))\n",
    "\n",
    "        loss = torch.mean(torch.tensor(loss_list))\n",
    "\n",
    "    if method == 'classification':\n",
    "        acc = torch.mean(torch.tensor(acc_list, dtype=torch.float32))\n",
    "        return loss, acc\n",
    "    elif method == 'regression':\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f30f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train function\n",
    "\n",
    "def train_model(model, train_dataset, test_dataset, batch = 256, epochs=50,\n",
    "                lr=0.005, class_weights = None, weight_decay = 0):\n",
    "\n",
    "    # train_history\n",
    "    train_history = {}\n",
    "    train_history['train_loss'] = []\n",
    "    train_history['train_acc'] = []\n",
    "\n",
    "    train_history['test_loss'] = []\n",
    "    train_history['test_acc'] = []\n",
    "\n",
    "    # set device\n",
    "    model, torch_device = set_device(model)\n",
    "    \n",
    "    if class_weights != None:\n",
    "        class_weights = class_weights.to(torch_device)\n",
    "\n",
    "    # Dataloader\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch, shuffle=True, drop_last=True)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=batch, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # optimzer and loss_func\n",
    "    optimzer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False)\n",
    "    loss_func = nn.CrossEntropyLoss(weight = class_weights)\n",
    "\n",
    "    # train_process\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for step, (inputs, labels) in enumerate(train_dl):\n",
    "            \n",
    "            inputs = inputs.to(torch_device)\n",
    "            labels = labels.to(torch_device)\n",
    "\n",
    "            out = model(inputs)\n",
    "            loss = loss_func(out, labels)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            \n",
    "            # output\n",
    "            train_loss, train_acc = evaluate(model, torch_device, loss_func, train_dl)\n",
    "            test_loss, test_acc = evaluate(model, torch_device, loss_func, test_dl)\n",
    "\n",
    "            print(  'Epoch:', epoch+1, '/', epochs, ', '\\\n",
    "                    'train_loss: {loss:.5f}, '.format(loss = train_loss), \\\n",
    "                    'train_acc: {acc:.5f}, '.format(acc = train_acc), \\\n",
    "                    'test_loss: {loss:.5f}, '.format(loss = test_loss), \\\n",
    "                    'test_acc: {acc:.5f}'.format(acc = test_acc))\n",
    "\n",
    "            train_history['train_loss'].append(train_loss)\n",
    "            train_history['train_acc'].append(train_acc)\n",
    "\n",
    "            train_history['test_loss'].append(test_loss)\n",
    "            train_history['test_acc'].append(test_acc)\n",
    "  \n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c82ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "cat_dataset = dataset(dataset_path)\n",
    "\n",
    "split_rate = 0.9\n",
    "train_size = int(split_rate * len(cat_dataset))\n",
    "test_size = len(cat_dataset) - train_size\n",
    "\n",
    "print(test_size)\n",
    "\n",
    "train_dataset, test_dataset = random_split(cat_dataset, [train_size, test_size])\n",
    "\n",
    "batch = 1024\n",
    "epochs = 1\n",
    "lr = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617959dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN                                      --                        --\n",
      "├─Sequential: 1-1                        [1024, 16, 55, 55]        --\n",
      "│    └─Conv2d: 2-1                       [1024, 16, 111, 111]      448\n",
      "│    └─BatchNorm2d: 2-2                  [1024, 16, 111, 111]      32\n",
      "│    └─ReLU: 2-3                         [1024, 16, 111, 111]      --\n",
      "│    └─MaxPool2d: 2-4                    [1024, 16, 55, 55]        --\n",
      "├─Sequential: 1-2                        [1024, 32, 13, 13]        --\n",
      "│    └─Conv2d: 2-5                       [1024, 32, 27, 27]        4,640\n",
      "│    └─BatchNorm2d: 2-6                  [1024, 32, 27, 27]        64\n",
      "│    └─ReLU: 2-7                         [1024, 32, 27, 27]        --\n",
      "│    └─MaxPool2d: 2-8                    [1024, 32, 13, 13]        --\n",
      "├─Sequential: 1-3                        [1024, 64, 3, 3]          --\n",
      "│    └─Conv2d: 2-9                       [1024, 64, 6, 6]          18,496\n",
      "│    └─BatchNorm2d: 2-10                 [1024, 64, 6, 6]          128\n",
      "│    └─ReLU: 2-11                        [1024, 64, 6, 6]          --\n",
      "│    └─MaxPool2d: 2-12                   [1024, 64, 3, 3]          --\n",
      "├─Linear: 1-4                            [1024, 10]                5,770\n",
      "├─Dropout: 1-5                           --                        --\n",
      "├─Linear: 1-6                            --                        (recursive)\n",
      "├─ReLU: 1-7                              [1024, 10]                --\n",
      "├─Linear: 1-8                            [1024, 2]                 22\n",
      "==========================================================================================\n",
      "Total params: 29,600\n",
      "Trainable params: 29,600\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 9.80\n",
      "==========================================================================================\n",
      "Input size (MB): 616.56\n",
      "Forward/backward pass size (MB): 3649.93\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 4266.61\n",
      "==========================================================================================\n",
      "Epoch: 1 / 1 , train_loss: 0.57705,  train_acc: 0.73158,  test_loss: 0.58905,  test_acc: 0.72021\n",
      "Epoch: 1 / 1 , train_loss: 0.44525,  train_acc: 0.79246,  test_loss: 0.44062,  test_acc: 0.79834\n",
      "Epoch: 1 / 1 , train_loss: 0.49038,  train_acc: 0.75814,  test_loss: 0.49553,  test_acc: 0.74707\n",
      "Epoch: 1 / 1 , train_loss: 0.47560,  train_acc: 0.76614,  test_loss: 0.48081,  test_acc: 0.75928\n",
      "Epoch: 1 / 1 , train_loss: 0.45685,  train_acc: 0.78278,  test_loss: 0.46135,  test_acc: 0.77002\n",
      "Epoch: 1 / 1 , train_loss: 0.45612,  train_acc: 0.78618,  test_loss: 0.46289,  test_acc: 0.77881\n",
      "Epoch: 1 / 1 , train_loss: 0.46350,  train_acc: 0.78292,  test_loss: 0.49425,  test_acc: 0.76562\n",
      "Epoch: 1 / 1 , train_loss: 0.44865,  train_acc: 0.78916,  test_loss: 0.44951,  test_acc: 0.78760\n",
      "Epoch: 1 / 1 , train_loss: 0.44115,  train_acc: 0.79408,  test_loss: 0.44573,  test_acc: 0.79590\n",
      "Epoch: 1 / 1 , train_loss: 0.42757,  train_acc: 0.80022,  test_loss: 0.43315,  test_acc: 0.78906\n",
      "Epoch: 1 / 1 , train_loss: 0.43036,  train_acc: 0.79813,  test_loss: 0.41939,  test_acc: 0.80176\n",
      "Epoch: 1 / 1 , train_loss: 0.42888,  train_acc: 0.79683,  test_loss: 0.43492,  test_acc: 0.79639\n",
      "Epoch: 1 / 1 , train_loss: 0.42895,  train_acc: 0.79748,  test_loss: 0.43425,  test_acc: 0.79395\n",
      "Epoch: 1 / 1 , train_loss: 0.42316,  train_acc: 0.80153,  test_loss: 0.41558,  test_acc: 0.80615\n",
      "Epoch: 1 / 1 , train_loss: 0.42299,  train_acc: 0.80218,  test_loss: 0.43704,  test_acc: 0.80469\n",
      "Epoch: 1 / 1 , train_loss: 0.43097,  train_acc: 0.79543,  test_loss: 0.44816,  test_acc: 0.78760\n",
      "Epoch: 1 / 1 , train_loss: 0.43227,  train_acc: 0.79990,  test_loss: 0.44276,  test_acc: 0.79297\n",
      "Epoch: 1 / 1 , train_loss: 0.42241,  train_acc: 0.80571,  test_loss: 0.45618,  test_acc: 0.78516\n",
      "Epoch: 1 / 1 , train_loss: 0.42164,  train_acc: 0.80501,  test_loss: 0.42414,  test_acc: 0.80273\n",
      "Epoch: 1 / 1 , train_loss: 0.42658,  train_acc: 0.80185,  test_loss: 0.43359,  test_acc: 0.79492\n",
      "Epoch: 1 / 1 , train_loss: 0.43264,  train_acc: 0.79664,  test_loss: 0.43638,  test_acc: 0.80273\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train Model\n",
    "\"\"\"\n",
    "\n",
    "# load model\n",
    "# model = Convnet(2)\n",
    "model = CNN()\n",
    "\n",
    "model_save_path = '/home/wyundi/Server/Courses/CS546/project/repo/M_Hub/src/ipynb/cat.pth'\n",
    "if os.path.exists(model_save_path):\n",
    "    model.load_state_dict(torch.load('/home/wyundi/Server/Courses/CS546/project/repo/M_Hub/src/ipynb/cat.pth'))\n",
    "print(summary(model, (batch, 3, 224, 224)))\n",
    "\n",
    "# train\n",
    "hist = train_model(model, train_dataset, test_dataset, batch, epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3664fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/wyundi/Server/Courses/CS546/project/repo/M_Hub/src/ipynb/cat.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895e85b2",
   "metadata": {},
   "source": [
    "## Export model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eaac2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=576, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "torch_model = model.eval()\n",
    "print(torch_model)\n",
    "\n",
    "# model input\n",
    "x = torch.randn((1, 3, 224, 224), requires_grad=True)\n",
    "torch_out = torch_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df88d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "onnx_path = '../onnx/cat.onnx'\n",
    "torch.onnx.export(model, x, onnx_path, export_params=True, do_constant_folding=True,\n",
    "                  input_names=['input'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a29b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test onnx model\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "check_res = onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f68b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': array([[[[-0.46013075,  0.16131048,  1.3411492 , ...,  0.47016093,\n",
      "           0.6627378 ,  0.01738982],\n",
      "         [ 1.393888  ,  2.077385  , -0.2751896 , ...,  0.96145153,\n",
      "           0.30042148,  0.79800147],\n",
      "         [ 0.05929932,  0.11774691,  1.064682  , ...,  1.0067812 ,\n",
      "          -0.77511686,  0.18467359],\n",
      "         ...,\n",
      "         [ 0.3249645 , -0.09760758, -0.8661106 , ...,  0.5851463 ,\n",
      "          -0.31697223,  1.4835749 ],\n",
      "         [-0.23666707, -0.0062504 , -0.07259718, ...,  0.35776502,\n",
      "           0.5893171 , -0.76672655],\n",
      "         [ 0.78680843, -0.3816563 ,  1.0277336 , ..., -0.03134407,\n",
      "          -0.04578843, -0.9389643 ]],\n",
      "\n",
      "        [[-0.4381995 ,  0.44542983, -0.84105694, ..., -0.61878425,\n",
      "          -0.7541752 , -0.22854093],\n",
      "         [ 0.2826845 ,  0.01130121,  1.9391162 , ...,  0.44259194,\n",
      "          -0.81699294,  0.20036478],\n",
      "         [ 0.81456697, -0.97180915,  1.6943713 , ..., -1.3432666 ,\n",
      "           0.8279068 , -0.7821024 ],\n",
      "         ...,\n",
      "         [ 0.57990557, -2.0709617 , -0.89426786, ..., -0.54241675,\n",
      "           0.90735424,  0.65143543],\n",
      "         [-1.9544338 ,  1.4001989 ,  0.775677  , ..., -0.9065638 ,\n",
      "           0.20360364,  1.2947872 ],\n",
      "         [ 0.07298647,  0.06913392, -1.0138165 , ...,  0.2772653 ,\n",
      "          -0.5550767 , -0.09066978]],\n",
      "\n",
      "        [[-0.0518376 ,  1.7668743 , -1.0283177 , ...,  1.2404449 ,\n",
      "          -0.7645952 , -0.29977772],\n",
      "         [-0.15636778,  0.10450761, -0.30428147, ...,  0.40067053,\n",
      "          -0.55441713,  0.32082862],\n",
      "         [-0.86842257,  0.22167532, -0.792903  , ...,  0.76633304,\n",
      "           1.7376118 , -1.1611001 ],\n",
      "         ...,\n",
      "         [ 0.2951191 , -0.8628042 ,  0.33598638, ...,  1.8558818 ,\n",
      "           1.559654  , -0.15103026],\n",
      "         [ 1.2448382 ,  1.2914267 ,  1.1279101 , ..., -1.8641042 ,\n",
      "          -0.15938564, -1.473558  ],\n",
      "         [ 0.11488654, -0.6089245 , -0.28716445, ..., -0.27182794,\n",
      "           0.5467165 , -0.45607138]]]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "ort_session = onnxruntime.InferenceSession(onnx_path)\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "print(ort_inputs)\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce6a0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9504, -1.2846]], grad_fn=<AddmmBackward0>)\n",
      "[array([[ 0.95036775, -1.2846333 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(torch_out)\n",
    "print(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ee4cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(torch_out.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
